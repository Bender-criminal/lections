# nginx

* **nginx** [engine x] — это HTTP-сервер и обратный прокси-сервер, почтовый прокси-сервер, а также TCP/UDP прокси-сервер общего назначения, изначально написанный Игорем Сысоевым.

---

* Уже длительное время он обслуживает серверы многих высоконагруженных российских сайтов, таких как Яндекс, Mail.Ru, ВКонтакте и Рамблер. Согласно статистике Netcraft nginx обслуживал или проксировал 25.76% самых нагруженных сайтов в сентябре 2020 года. Вот некоторые примеры успешного внедрения nginx (тексты на английском языке): Dropbox, Netflix, Wordpress.com, FastMail.FM.

* Исходные тексты и документация распространяются под BSD-подобной лицензией из 2 пунктов.

* Коммерческая поддержка осуществляется компанией Nginx, Inc.

## Основная функциональность HTTP-сервера

* Обслуживание статических запросов, индексных файлов, автоматическое создание списка файлов, кэш дескрипторов открытых файлов;
* Акселерированное обратное проксирование с кэшированием, распределение нагрузки и отказоустойчивость;
* Акселерированная поддержка FastCGI, uwsgi, SCGI и memcached серверов с кэшированием, распределение нагрузки и отказоустойчивость;
* Модульность, фильтры, в том числе сжатие (gzip), byte-ranges (докачка), chunked ответы, XSLT-фильтр, SSI-фильтр, преобразование изображений; несколько подзапросов на одной странице, обрабатываемые в SSI-фильтре через прокси или FastCGI/uwsgi/SCGI, выполняются параллельно;
* Поддержка SSL и расширения TLS SNI;
* Поддержка HTTP/2 с приоритизацией на основе весов и зависимостей.

## Другие возможности HTTP-сервера

* Виртуальные серверы, определяемые по IP-адресу и имени;
* Поддержка keep-alive и pipelined соединений;
* Настройка форматов логов, буферизованная запись в лог, быстрая ротация логов, запись в syslog;
* Специальные страницы для ошибок 3xx-5xx;
* rewrite-модуль: изменение URI с помощью регулярных выражений;
* Выполнение разных функций в зависимости от адреса клиента;
* Ограничение доступа в зависимости от адреса клиента, по паролю (HTTP Basic аутентификация) и по результату подзапроса;
* Проверка HTTP referer;
* Методы PUT, DELETE, MKCOL, COPY и MOVE;
* FLV и MP4 стриминг;
* Ограничение скорости отдачи ответов;
* Ограничение числа одновременных соединений и запросов с одного адреса;
* Геолокация по IP-адресу;
* A/B-тестирование;
* Зеркалирование запросов;
* Встроенный Perl;
* сценарный язык njs.


## Функциональность почтового прокси-сервера

* Перенаправление пользователя на IMAP- или POP3-сервер с использованием внешнего HTTP-сервера аутентификации;
* Проверка пользователя с помощью внешнего HTTP-сервера аутентификации и перенаправление соединения на внутренний SMTP-сервер;
* Методы аутентификации:
	* POP3: USER/PASS, APOP, AUTH LOGIN/PLAIN/CRAM-MD5;
	* IMAP: LOGIN, AUTH LOGIN/PLAIN/CRAM-MD5;
	* SMTP: AUTH LOGIN/PLAIN/CRAM-MD5;
* Поддержка SSL;
* Поддержка STARTTLS и STLS.


## Функциональность TCP/UDP прокси-сервера

* Проксирование TCP и UDP;
* Поддержка SSL и расширения TLS SNI для TCP;
* Распределение нагрузки и отказоустойчивость;
* Ограничение доступа в зависимости от адреса клиента;
* Выполнение разных функций в зависимости от адреса клиента;
* Ограничение числа одновременных соединений с одного адреса;
* Настройка форматов логов, буферизованная запись в лог, быстрая ротация логов, запись в syslog;
* Геолокация по IP-адресу;
* A/B-тестирование;
* сценарный язык njs.


## Архитектура и масштабируемость
* Один главный и несколько рабочих процессов, рабочие процессы работают под непривилегированным пользователем;
* Гибкость конфигурации;
* Изменение настроек и обновление исполняемого файла без перерыва в обслуживании клиентов;
* Поддержка kqueue (FreeBSD 4.1+), epoll (Linux 2.6+), /dev/poll (Solaris 7 11/99+), event ports (Solaris 10), select и poll;
* Использование возможностей, предоставляемых kqueue, таких как EV_CLEAR, EV_DISABLE (для временного выключения события), NOTE_LOWAT, EV_EOF, число доступных данных, коды ошибок;
* Использование возможностей, предоставляемых epoll, таких как EPOLLRDHUP (Linux 2.6.17+, glibc 2.8+) и EPOLLEXCLUSIVE (Linux 4.5+, glibc 2.24+);
* Поддержка sendfile (FreeBSD 3.1+, Linux 2.2+, macOS 10.5+), sendfile64 (Linux 2.4.21+) и sendfilev (Solaris 8 7/01+);
* Поддержка файлового AIO (FreeBSD 4.3+, Linux 2.6.22+);
* Поддержка DIRECTIO (FreeBSD 4.4+, Linux 2.4+, Solaris 2.6+, macOS);
* Поддержка accept-фильтров (FreeBSD 4.1+, NetBSD 5.0+) и TCP_DEFER_ACCEPT (Linux 2.4+);
* На 10 000 неактивных HTTP keep-alive соединений расходуется около 2.5M памяти;
* Минимум операций копирования данных.


## Протестированные ОС и платформы

* FreeBSD 3 — 12 / i386; FreeBSD 5 — 12 / amd64;
* FreeBSD 11 / ppc; FreeBSD 12 / ppc64;
* Linux 2.2 — 4 / i386; Linux 2.6 — 5 / amd64; Linux 3 — 4 / armv6l, armv7l, aarch64, ppc64le;
* Solaris 9 / i386, sun4u; Solaris 10 / i386, amd64, sun4v; Solaris 11 / x86;
* AIX 7.1 / powerpc;
* HP-UX 11.31 / ia64;
* macOS / ppc, i386, x86_64;
* Windows XP, Windows Server 2003, Windows 7, Windows 10.

---

# Reverse Proxy (Обратный прокси)

* **Reverse Proxy** - тип прокси-сервера, который ретранслирует запросы клиентов из внешней сети на один или несколько серверов, логически расположенных во внутренней сети. 
* При этом для клиента это выглядит так, будто запрашиваемые ресурсы находятся непосредственно на прокси-сервере.
* В отличие от классического прокси, который перенаправляет запросы клиентов к любым серверам в Интернете и возвращает им результат, обратный прокси непосредственно взаимодействует лишь с ассоциированными с ним серверами и возвращает ответ только от них.


## Использование

* Обратный прокси-сервер может скрывать существование опрашиваемых им серверов и их характеристики.
* Применение программного файрвола (брандмауэр) в обратном прокси-сервере может защитить от наиболее распространенных веб-атак, таких как DOS или DDOS. Без обратного прокси-сервера удаление вредоносного ПО может оказаться непростой задачей.
* Основной веб-сайт может не поддерживать подключение по SSL, однако это можно реализовать с помощью обратного прокси-сервера, который может быть оборудован аппаратным SSL-ускорителем.
* Выполнение функций балансировщика нагрузки между несколькими серверами, подменяя URL таким образом, чтобы использовался наиболее уместный сервер.
* Уменьшение нагрузки на основные сервера благодаря кэшированию статического и динамического контента. Эта возможность известна как акселерация веб-сайтов. Сервер может отсортировать свой кэш по частоте запросов к контенту, что значительно уменьшит нагрузку на основные серверы.
* Сжатие содержимого для уменьшения времени его загрузки.
* В методе, называемом «spoon feeding», страницы, генерируемые динамически, могут быть отданы серверу и обработаны уже им.
* Может выполнять тестирование, например, A/B-тестирование, изменяя код страниц. Полученные данные можно использовать для последующей оптимизации.

---

# HAProxy

* **HAProxy** — серверное программное обеспечение для обеспечения высокой доступности и балансировки нагрузки для TCP и HTTP-приложений, посредством распределения входящих запросов на несколько обслуживающих серверов. Программа написана на языке **C**.

---

* HAProxy используется в ряде высоконагруженных веб-сайтов, включая Twitter, Instagram, Github, Stack Overflow, Reddit, Tumblr, DeviantArt, Avito и OpsWorks product из Amazon Web Services, W3C (W3C Validator), а также является частью облачной платформы Red Hat OpenShift и балансировщиком по умолчанию в облачной платформе OpenStack.

* HAProxy является программой с открытым исходным кодом и распространяется в соответствии с GNU General Public License (GNU GPL v2).


## Возможности

* Периодическая проверка доступности обслуживающих (back-end) серверов, на которые перенаправляются запросы пользователей;
* Несколько алгоритмов определения доступности сервера: tcp-check, http-check, mysql-check;
* Балансировка HTTP / HTTPS / TCP-запросов между «живыми» серверами;
* Поддержка TLS SNI для различения HTTPS-обращений к разным сайтам;
* Возможность закрепления определенных клиентов за конкретными обслуживающими серверами (stick-tables);
* Поддержка: IPv6 и UNIX sockets, HTTP/1.1 сжатие (deflate, gzip, libslz), SSL-шифрование, полная поддержка постоянного HTTP-соединения;
* Поддержка переменных, цитирования блоков и Lua-скриптов в конфигурации сервера;
* Веб-интерфейс с актуальным состоянием и статистикой работы программы;
* Поддержка HTTP/2.


## Производительность

* **2007 год**: Типичные 1U сервера оснащённые двухъядерным процессором Opteron или Xeon обычно достигали производительности от 15 000 до 40 000 запросов/сек и не имели проблем с обслуживанием потока до 2 Гбит/с под ОС Linux.[9]
* **2014 год**: 1U сервера оснащённые Xeon E5 (2014 года) и 10 Гбит/с сетевой картой без проблем обрабатывают поток 40—60 Гбит/с, при этом подчёркивается, что ограничивающим фактором является пропускная способность сетевой карты.
	* Даже на процессоре Intel Atom 1,6 ГГц (с пассивным воздушным охлаждением) HAProxy удалось обрабатывать поток до 1 ГБит/с.[10]

* **Расход памяти**: 1 Гб ОЗУ хватает для обслуживания ~20 000—30 000 одновременных сессий.


## История

* Willy Tarreau  (один из основных разработчиков ядра Linux) написал HAProxy в 2000 году и до сих пор занимается её разработкой.

* В 2015 году, подводя итоги релиза HAProxy 1.6, Вилли отметил, что из более чем 1150 коммитов принятых в ветку 1.6, более 1/3 были сделаны сообществом.

---

# Polling vs Callback

## Polling

* Самый простой способ получать новую информацию от сервера – периодический опрос. То есть, регулярные запросы на сервер вида: «Привет, я здесь, у вас есть какая-нибудь информация для меня?». Например, раз в 10 секунд.

* В ответ сервер, во-первых, помечает у себя, что клиент онлайн, а во-вторых посылает весь пакет сообщений, накопившихся к данному моменту.

### Это работает, но есть и недостатки:

* Сообщения передаются с задержкой до 10 секунд (между запросами).
* Даже если сообщений нет, сервер «атакуется» запросами каждые 10 секунд, даже если пользователь переключился куда-нибудь или спит. С точки зрения производительности, это довольно большая нагрузка.
* Так что, если речь идёт об очень маленьком сервисе, подход может оказаться жизнеспособным, но в целом он нуждается в улучшении.

## Long Polling

* Чтобы сэкономить на ресурсах, можно использовать long polling. Устроен он так же, как и polling, с одним отличием: сервер дольше отвечает. Вообще, при лонг-поллинге сервер отвечает в двух случаях: или потому, что пришло новое сообщение, или потому, что соединение пора разрывать.

* У каждого запроса есть timeout — время, в течении которого нужно ответить. Если на запрос не ответили за это время, считается, что сервер не ответит вообще. Поэтому сервер смотрит на timeout и решает так:

* Если за это время у меня не появится обновлений для клиента, я отвечу ему, что их нет.
* Если появятся, я отправлю ему обновления сразу, не дожидаясь таймаута.
* Чтобы реализовать long polling на стороне клиента, нужно выставить большой timeout: 30 или 60 секунд.

## Callback

* Это значит, что создается сервер, который принимает запросы, ждет, когда ему что-то дадут, и, когда ему что-то дают, он сразу обрабатывает полученную информацию.
* В отличие от LongPoll API, на Callback сервер за один запрос отправляется не много событий сразу, а только одно.

---

# ESB - Сервисная шина предприятия

* Сервисная шина предприятия (англ. enterprise service bus, ESB) — связующее программное обеспечение, обеспечивающее централизованный и унифицированный событийно-ориентированный обмен сообщениями между различными информационными системами на принципах сервис-ориентированной архитектуры. Понятие введено в начале 2000-х годов специалистами подразделения Progress Software — Sonic, разрабатывавшими MOM-продукт SonicMQ

## Архитектура

* ESB обеспечивает унифицированное взаимодействие между службами, созданными в различных средах
* Основной принцип сервисной шины — концентрация обмена сообщениями между различными системами через единую точку, в которой, при необходимости, обеспечивается транзакционный контроль, преобразование данных, сохранность сообщений. Все настройки обработки и передачи сообщений предполагаются также сконцентрированными в единой точке, и формируются в терминах служб, таким образом, при замене какой-либо информационной системы, подключённой к шине, нет необходимости в перенастройке остальных систем.

* Наименование подобрано по аналогии с системной шиной компьютера, позволяющей подключать несколько устройств и передавать данные между ними по одному набору проводников.

## Основные характеристики

«Сервисная шина предприятия» является зонтичным термином для набора возможностей, которые в разных реализациях трактуются несколько различными способами. Как правило, выделяются следующие ключевые возможности:

* поддержка синхронного и асинхронного способа вызова служб;
* использование защищённого транспорта, с гарантированной доставкой сообщений, поддерживающего транзакционную модель;
* статическая и алгоритмическая маршрутизация сообщений;
* доступ к данным из сторонних информационных систем с помощью готовых или специально разработанных адаптеров;
* обработка и преобразование сообщений;
* оркестровка и хореография служб;
* разнообразные механизмы контроля и управления (аудиты, протоколирование).

Конкретные программные продукты обычно также содержат готовые адаптеры для соединения с конкретным прикладным программным обеспечением, а также могут включать API для создания таких адаптеров.


## Программные продукты

По состоянию на вторую половину 2011 года Forrester относит к «волне лидеров» следующие продукты со значительным присутствием на рынке: WebMethods ESB (Software AG, семейство продуктов WebMethods, поглощённой одноимённой компанией), ActiveMatrix Service Bus (Tibco), Oracle Service Bus (Oracle, семейство Fusion Middleware), WebSphere Message Broker (IBM, семейство WebSphere). Среди продуктов с менее значительным присутствием на рынке упомянуты Sonic ESB (Progress Software), WebSphere ESB и ESBRE (IBM), FuseSource, с незначительным — MuleESB, WSO2, JBoss ESB (Red Hat).

---

# Система обмена сообщениями

* **Система обмена сообщениями** - это система, принимающая сообщение у отправителя и доставляющая его получателю. Мы можем написать систему обмена сообщениями сами, можем использовать ØMQ, а можем взять какую-нибудь монструозную MoM. Но любая из этих систем должна давать гарантии того, сколько раз отправленное сообщение может быть доставлено получателю при возникновении проблем.

* Гарантии определяют надежность доставки сообщения. Технически оправдано гарантировать один из следующих вариантов:
	* **at-most-once** - сообщение может быть доставлено 0 или 1 раз. Проще говоря сообщение может быть потеряно. Самый простой и эффективный способ доставки сообщений. Гарантий никаких.
	* **at-least-once** - сообщение может быть доставлено 1 и более раз. При ошибке доставки может быть предпринято несколько попыток отправить одно и то же сообщение. Поэтому могут возникнуть дубликаты, но потерянных сообщения быть не может. Этот способ сложнее чем at-most-once.
	* **exactly-once** - гарантированна доставка сообщения строго один раз. Именно этот вариант возникает по умолчанию в голове некоторых горе-программистов при упоминании любой системы обмена сообщениями. На практике же встречается достаточно редко.
 
 ---
 
 # Message-driven / Event-driven

На примере службы заказов, когда нужно согласовать порядок отправки запроса на авторизацию кредитной карты из их службы в вашу. Есть два варианта:

* **Message-driven**: при размещении заказа служба заказов отправляет запрос авторизации в вашу платежную службу. Ваша служба обрабатывает запрос и возвращает успех/неудачу службе заказов. Первоначальный запрос и результат могут быть отправлены синхронно или асинхронно.

* **Event=driven**: при размещении заказа служба заказов публикует событие NewOrder. Ваша Платежная служба подписывается на событие этого типа, поэтому оно инициируется. Ваша служба обрабатывает запрос и публикует событие AuthorizationAccepted или AuthorizationDeclined. Служба заказов подписывается на эти типы событий. Все события асинхронны.


* Преимущество подхода, основанного на событиях, заключается в том, что другие службы также могут подписываться на различные события.
	* Например, может существовать служба RevenueReporting, которая подписывается на события AuthorizationAccepted и создает отчеты для финансовой группы.

* Недостатком подхода, основанного на событиях, является то, что система в целом становится немного сложнее для понимания.
	* Например, предположим, что команда, работающая над службой заказа, просит вас заменить событие AuthorizationDeclined различными событиями в зависимости от того, почему кредитная карта была отклонена (нет средств, счет закрыт, неверный адрес выставления счета и т. Д.).
	* Если вы перестанете публиковать события AuthorizationDeclined, не сломается ли это какой-нибудь другой сервис?
	* Если у вас много мероприятий и услуг, это может быть сложно отследить.
  
 ---
 
 # Шардирование, репликация и партицирование

## Репликация

* **Репликация** позволяет создать полный дубликат базы данных.
* Так, вместо одного сервера у Вас их будет несколько:
	
### Master-slave

* Чаще всего используют схему master-slave:
	* Master — это основной сервер БД, куда поступают все данные. Все изменения в данных (добавление, обновление, удаление) должны происходить на этом сервере.
	* Slave — это вспомогательный сервер БД, который копирует все данные с мастера. С этого сервера следует читать данные. Таких серверов может быть несколько.


* Репликация позволяет использовать два или больше одинаковых серверов вместо одного. Операций чтения (SELECT) данных часто намного больше, чем операций изменения данных (INSERT/UPDATE). Поэтому, репликация позволяет разгрузить основной сервер за счет переноса операций чтения на слейв.

## Шардирование

* **Шардирование** — это другая техника масштабирования работы с данными. Суть его в разделении (партиционирование) базы данных на отдельные части так, чтобы каждую из них можно было вынести на отдельный сервер. Этот процесс зависит от структуры Вашей базы данных и выполняется прямо в приложении в отличие от репликации:

### Вертикальный шардинг

* **Вертикальный шардинг** — это выделение таблицы или группы таблиц на отдельный сервер.

### Горизонтальный шардинг

* **Горизонтальный шардинг** — это разделение одной таблицы на разные сервера. Это необходимо использовать для огромных таблиц, которые не умещаются на одном сервере.


* Не следует применять технику шардинга ко всем таблицам. Правильный подход — это поэтапный процесс разделения растущих таблиц. Следует задумываться о горизонтальном шардинге, когда количество записей в одной таблице переходит за пределы от нескольких десятков миллионов до сотен миллионов.

### Совместное использование

* Шардинг и репликация часто используются совместно.
* 

## Партицирование

* **Партицирование** - разделение хранимых объектов баз данных (таких как таблиц, индексов, материализованных представлений) на отдельные части с раздельными параметрами физического хранения. Используется в целях повышения управляемости, производительности и доступности для больших баз данных.

* Возможные критерии разделения данных, используемые при секционировании: 
	* по предопределённым диапазонам значений;
	* по спискам значений
	* при помощи значений хеш-функций;
	* в некоторых случаях используются другие варианты.
* Под композитными (составными) критериями разделения понимают последовательно применённые критерии разных типов.

* В отличие от **шардирования**, где каждый сегмент управляется отдельным экземпляром СУБД, и используются средства координации между ними (что позволяет распределить базу данных на несколько вычислительных узлов), при **партицировании** доступ ко всем секциям осуществляется из единого экземпляра СУБД (или симметрично из любого экземпляра кластерной СУБД, такого, как Oracle RAC).

---

# Circuit Breaker Pattern

* Паттерн Circuit Breaker предотвращает попытки приложения выполнить операцию, которая скорее всего завершится неудачно, что позволяет продолжить работу дальше не тратя важные ресурсы, пока известно, что проблема не устранена. Приложение должно быстро принять сбой операции и обработать его.
* Он также позволяет приложению определять, была ли устранена неисправность. Если проблема устранена, приложение может попытаться вызвать операцию снова.

* У Circuit Breaker есть 3 состояния:

1. **Closed**
	* Запрос приложения перенаправляется на операцию. Прокси-сервер ведет подсчет числа недавних сбоев, и если вызов операции не завершился успешно, прокси-сервер увеличивает это число.
	* Если число недавних сбоев превышает заданный порог в течение заданного периода времени, прокси-сервер переводится в состояние Открытый. На этом этапе прокси-сервер запускает таймер времени ожидания, и по истечении времени этого таймера прокси-сервер переводится в состояние Half-Open.
	* Цель применения этого паттерна — дать системе время на исправление ошибки, которая вызвала сбой, прежде чем разрешить приложению попытаться выполнить операцию еще раз.
	* Назначение таймера — дать сервису время для решения проблемы, прежде чем разрешить приложению попытаться выполнить операцию еще раз.

2. **Open**:
  * Запрос от приложения немедленно завершает с ошибкой и исключение возвращается в приложение.

3. **Half-Open**:
	* Ограниченному числу запросов от приложения разрешено проходить через операцию и вызывать ее.
	* Если эти запросы выполняются успешно, предполагается, что ошибка, которая ранее вызывала сбой, устранена, а автоматический выключатель переходит в состояние Закрытый (счетчик сбоев сбрасывается).
	* Если какой-либо запрос завершается со сбоем, автоматическое выключение предполагает, что неисправность все еще присутствует, поэтому он возвращается в состояние Открытый и перезапускает таймер времени ожидания, чтобы дать системе дополнительное время на восстановление после сбоя.


* Состояние **Half-Open** помогает предотвратить быстрый рост запросов к сервису. Т.к. после начала работы сервиса, некоторое время он может быть способен обрабатывать ограниченное число запросов до полного восстановления.


* Шаблон **Circuit Breaker** обеспечивает стабильность, пока система восстанавливается после сбоя и снижает влияние на производительность.

---
  
 # Дополнительные источники
 
 * [Microservices. Как правильно делать и когда применять?](https://habr.com/ru/company/dataart/blog/280083/)
